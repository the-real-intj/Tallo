# -*- coding: utf-8 -*-
"""
ìŒì„± ì¸ì‹ ëª¨ë“ˆ (Speech-to-Text)
- OpenAI Whisper (ë¡œì»¬ ì‹¤í–‰)
"""

import os
import logging
import numpy as np
from typing import Optional, Tuple
from pathlib import Path

logger = logging.getLogger(__name__)


class WhisperSTT:
    """
    OpenAI Whisper ìŒì„± ì¸ì‹
    - ì™„ì „ ë¬´ë£Œ (ë¡œì»¬ ì‹¤í–‰)
    - ê³ í’ˆì§ˆ í•œêµ­ì–´ ì¸ì‹
    """

    def __init__(self, model_size: str = "base", device: Optional[str] = None):
        """
        Args:
            model_size: ëª¨ë¸ í¬ê¸°
                - tiny: 39M, ë¹ ë¦„, ì •í™•ë„ ë‚®ìŒ
                - base: 74M, ê· í˜• (ì¶”ì²œ - í…ŒìŠ¤íŠ¸ìš©)
                - small: 244M, ëŠë¦¼, ì •í™•ë„ ë†’ìŒ
                - medium: 769M, ë§¤ìš° ëŠë¦¼, ì •í™•ë„ ë§¤ìš° ë†’ìŒ
                - large: 1550M, ìµœê³  í’ˆì§ˆ (GPU í•„ìˆ˜)
            device: ì‹¤í–‰ ì¥ì¹˜ (cuda, cpu, mps)
        """
        try:
            import whisper
            import torch
        except ImportError:
            raise ImportError(
                "whisper íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n"
                "ì„¤ì¹˜: pip install openai-whisper torch"
            )

        self.model_size = model_size

        # ë””ë°”ì´ìŠ¤ ìë™ ì„¤ì •
        if device is None:
            if torch.cuda.is_available():
                device = "cuda"
            elif hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
                device = "mps"  # Mac M1/M2
            else:
                device = "cpu"

        self.device = device

        logger.info(f"ğŸ¤ Whisper ëª¨ë¸ ë¡œë”© ì¤‘... (í¬ê¸°: {model_size}, ì¥ì¹˜: {device})")
        self.model = whisper.load_model(model_size, device=device)
        logger.info("âœ… Whisper ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    def transcribe_file(
        self,
        audio_path: str,
        language: str = "ko",
        verbose: bool = False
    ) -> dict:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´ ì½”ë“œ (ko, en, ja, zh ë“±)
            verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥

        Returns:
            {
                "text": "ë³€í™˜ëœ í…ìŠ¤íŠ¸",
                "language": "ko",
                "segments": [...],  # íƒ€ì„ìŠ¤íƒ¬í”„ë³„ ì„¸ê·¸ë¨¼íŠ¸
            }
        """
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}")

        logger.info(f"ğŸ§ ìŒì„± ì¸ì‹ ì¤‘... ({audio_path})")

        result = self.model.transcribe(
            audio_path,
            language=language,
            verbose=verbose,
            fp16=False if self.device == "cpu" else True
        )

        logger.info(f"âœ… ì¸ì‹ ì™„ë£Œ: {result['text'][:50]}...")
        return result

    def transcribe_audio_data(
        self,
        audio_data: np.ndarray,
        sample_rate: int = 16000,
        language: str = "ko"
    ) -> str:
        """
        ì˜¤ë””ì˜¤ ë°ì´í„° (numpy array)ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

        Args:
            audio_data: ì˜¤ë””ì˜¤ ë°ì´í„° (numpy array)
            sample_rate: ìƒ˜í”Œë§ ë ˆì´íŠ¸
            language: ì–¸ì–´ ì½”ë“œ

        Returns:
            ë³€í™˜ëœ í…ìŠ¤íŠ¸
        """
        import tempfile
        from scipy.io.wavfile import write

        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
            tmp_path = tmp_file.name

            # ì •ê·œí™” (float32 â†’ int16)
            if audio_data.dtype == np.float32 or audio_data.dtype == np.float64:
                audio_data = np.clip(audio_data, -1.0, 1.0)
                audio_data = (audio_data * 32767).astype(np.int16)

            write(tmp_path, sample_rate, audio_data)

        try:
            result = self.transcribe_file(tmp_path, language=language)
            return result["text"]
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(tmp_path):
                os.remove(tmp_path)

    def record_and_transcribe(
        self,
        duration: int = 5,
        sample_rate: int = 16000,
        language: str = "ko"
    ) -> str:
        """
        ë§ˆì´í¬ë¡œ ë…¹ìŒí•˜ê³  ì¦‰ì‹œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

        Args:
            duration: ë…¹ìŒ ì‹œê°„ (ì´ˆ)
            sample_rate: ìƒ˜í”Œë§ ë ˆì´íŠ¸
            language: ì–¸ì–´ ì½”ë“œ

        Returns:
            ë³€í™˜ëœ í…ìŠ¤íŠ¸
        """
        try:
            import sounddevice as sd
        except ImportError:
            raise ImportError(
                "sounddevice íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n"
                "ì„¤ì¹˜: pip install sounddevice"
            )

        print(f"ğŸ¤ {duration}ì´ˆê°„ ë…¹ìŒ ì‹œì‘...")

        # ë…¹ìŒ
        audio_data = sd.rec(
            int(duration * sample_rate),
            samplerate=sample_rate,
            channels=1,
            dtype=np.float32
        )
        sd.wait()

        print("âœ… ë…¹ìŒ ì™„ë£Œ! í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘...")

        # ë³€í™˜
        text = self.transcribe_audio_data(
            audio_data.flatten(),
            sample_rate=sample_rate,
            language=language
        )

        return text


class GeminiSTT:
    """
    Gemini ìŒì„± ì¸ì‹ (ëŒ€ì•ˆ)
    - Gemini 1.5 FlashëŠ” ì˜¤ë””ì˜¤ ì…ë ¥ ì§€ì›
    - ìœ ë£Œì§€ë§Œ í’ˆì§ˆ í‰ê°€ ë“± ë¶€ê°€ ê¸°ëŠ¥ ê°€ëŠ¥
    """

    def __init__(self):
        try:
            import google.generativeai as genai
        except ImportError:
            raise ImportError(
                "google-generativeai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n"
                "ì„¤ì¹˜: pip install google-generativeai"
            )

        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key or api_key == "your_gemini_api_key_here":
            raise ValueError("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        genai.configure(api_key=api_key)
        self.genai = genai

        # Gemini 1.5 Flash (ì˜¤ë””ì˜¤ ì§€ì›)
        self.model = genai.GenerativeModel("gemini-1.5-flash")

        logger.info("âœ… Gemini STT ì´ˆê¸°í™” ì™„ë£Œ")

    def transcribe_file(self, audio_path: str, language: str = "ko") -> str:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (+ í’ˆì§ˆ í‰ê°€)

        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            language: ì–¸ì–´

        Returns:
            ë³€í™˜ëœ í…ìŠ¤íŠ¸
        """
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}")

        # íŒŒì¼ ì—…ë¡œë“œ
        audio_file = self.genai.upload_file(audio_path)

        # í”„ë¡¬í”„íŠ¸
        prompt = f"""
        ì´ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

        ì–¸ì–´: {language}

        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
        [í…ìŠ¤íŠ¸]
        ë³€í™˜ëœ í…ìŠ¤íŠ¸ ë‚´ìš©

        [í’ˆì§ˆ]
        - ìŒì§ˆ: (ì¢‹ìŒ/ë³´í†µ/ë‚˜ì¨)
        - ë°°ê²½ ë…¸ì´ì¦ˆ: (ìˆìŒ/ì—†ìŒ)
        - ê°ì •: (ê¸°ì¨/ìŠ¬í””/ì¤‘ë¦½ ë“±)
        """

        response = self.model.generate_content([audio_file, prompt])

        return response.text


# íŒ©í† ë¦¬ í•¨ìˆ˜
def create_stt(method: str = "whisper", **kwargs):
    """
    STT ì—”ì§„ ìƒì„±

    Args:
        method: "whisper" ë˜ëŠ” "gemini"
        **kwargs: ì¶”ê°€ ì„¤ì •

    Returns:
        STT ì¸ìŠ¤í„´ìŠ¤
    """
    if method == "whisper":
        return WhisperSTT(**kwargs)
    elif method == "gemini":
        return GeminiSTT(**kwargs)
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” STT ë°©ì‹: {method}")


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)

    print("ğŸ¤ Whisper STT í…ŒìŠ¤íŠ¸\n")

    # Whisper ì´ˆê¸°í™”
    stt = create_stt(method="whisper", model_size="base")

    # ë…¹ìŒ í…ŒìŠ¤íŠ¸
    print("\në…¹ìŒì„ ì‹œì‘í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
    input()

    text = stt.record_and_transcribe(duration=5)
    print(f"\nâœ… ì¸ì‹ ê²°ê³¼: {text}")
