"""
Zonos Multi-Character TTS API Server
ì—¬ëŸ¬ ìºë¦­í„°ì˜ Speaker Embeddingì„ ê´€ë¦¬í•˜ê³  TTSë¥¼ ìƒì„±í•˜ëŠ” FastAPI ì„œë²„
"""

from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.responses import FileResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import Optional, List, Dict
import torch
import torchaudio
import tempfile
import os
import json
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

from zonos.model import Zonos
from zonos.conditioning import make_cond_dict
from zonos.utils import DEFAULT_DEVICE as device

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# service ë””ë ‰í† ë¦¬ì˜ .env íŒŒì¼ ì‚¬ìš©
BASE_DIR = Path(__file__).parent.parent
load_dotenv(BASE_DIR / ".env")

# OpenAI LLM ì§€ì›
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸ OpenAI íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LLM ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install openai'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

# MongoDB ì§€ì›
try:
    from pymongo import MongoClient
    from pymongo.errors import ConnectionFailure
    MONGODB_AVAILABLE = True
except ImportError:
    MONGODB_AVAILABLE = False
    print("âš ï¸ MongoDB íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. MongoDB ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install pymongo'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

# torch.compile ë¹„í™œì„±í™” (Windows ì»´íŒŒì¼ëŸ¬ ì—†ìŒ)
import torch._dynamo
torch._dynamo.config.suppress_errors = True
os.environ["TORCHDYNAMO_DISABLE"] = "1"

# ==================== ì„¤ì • ====================
app = FastAPI(
    title="Zonos Multi-Character TTS API",
    version="2.0.0",
    description="ë‹¤ì¤‘ ìºë¦­í„° ìŒì„± ìƒì„± ë° ê´€ë¦¬ ì‹œìŠ¤í…œ"
)

# CORS ì„¤ì • (Reactì™€ í†µì‹  + ngrok)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  origin í—ˆìš© (ê°œë°œìš©)
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë””ë ‰í† ë¦¬ ì„¤ì • (ì´ë¯¸ ìœ„ì—ì„œ ì •ì˜ë¨)
EMBEDDINGS_DIR = BASE_DIR / "embeddings"
REFERENCE_DIR = BASE_DIR / "audios"
OUTPUTS_DIR = BASE_DIR / "outputs"
CACHE_DIR = BASE_DIR / "cache"

for directory in [EMBEDDINGS_DIR, REFERENCE_DIR, OUTPUTS_DIR, CACHE_DIR]:
    directory.mkdir(exist_ok=True)

# ìºë¦­í„° ë©”íƒ€ë°ì´í„° íŒŒì¼
CHARACTERS_DB = EMBEDDINGS_DIR / "characters.json"

# ì „ì—­ ë³€ìˆ˜
model = None
characters_db: Dict = {}
story_audio_cache: Dict[str, Dict[int, str]] = {}  # {character_id: {page_num: audio_path}}
mongodb_client = None
mongodb_db = None

# ==================== ë°ì´í„° ëª¨ë¸ ====================

class TTSRequest(BaseModel):
    """TTS ìƒì„± ìš”ì²­"""
    text: str
    character_id: str
    language: str = "ko"  # í•œêµ­ì–´ ê¸°ë³¸ê°’
    speaking_rate: float = 1.0
    pitch: float = 1.0
    emotion: Optional[str] = None  # happy, sad, angry, fear

class CharacterInfo(BaseModel):
    """ìºë¦­í„° ì •ë³´"""
    id: str
    name: str
    description: Optional[str] = None
    language: str = "ko"  # í•œêµ­ì–´ ê¸°ë³¸ê°’
    created_at: str
    reference_audio: Optional[str] = None

class CreateCharacterRequest(BaseModel):
    """ìºë¦­í„° ìƒì„± ìš”ì²­"""
    name: str
    description: Optional[str] = None
    language: str = "ko"  # í•œêµ­ì–´ ê¸°ë³¸ê°’

class StoryPage(BaseModel):
    """ë™í™” í˜ì´ì§€ ì •ë³´"""
    page: int
    text: str
    audio_url: Optional[str] = None  # í˜ì´ì§€ë³„ ì˜¤ë””ì˜¤ íŒŒì¼ URL

class PreGenerateStoryRequest(BaseModel):
    """ë™í™”ì±… ì „ì²´ TTS ë¯¸ë¦¬ ìƒì„± ìš”ì²­"""
    character_id: str
    pages: List[Dict]  # [{page: 1, text: "..."}, ...]

class LLMChatRequest(BaseModel):
    """LLM ì±„íŒ… ìš”ì²­"""
    message: str = Field(..., description="ì‚¬ìš©ì ë©”ì‹œì§€")
    character_id: Optional[str] = Field(None, description="ìºë¦­í„° ID (TTSì— ì‚¬ìš©)")
    character_name: Optional[str] = Field(None, description="ìºë¦­í„° ì´ë¦„ (í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©)")
    system_prompt: Optional[str] = Field(None, description="ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì„ íƒ)")
    return_audio: bool = Field(True, description="TTS ì˜¤ë””ì˜¤ë„ í•¨ê»˜ ë°˜í™˜í• ì§€ ì—¬ë¶€")

class LLMChatResponse(BaseModel):
    """LLM ì±„íŒ… ì‘ë‹µ"""
    text: str
    audio_url: Optional[str] = None  # TTS ìƒì„±ëœ ì˜¤ë””ì˜¤ URL

class StoryPage(BaseModel):
    """ë™í™” í˜ì´ì§€ ì •ë³´"""
    page: int
    text: str
    audio_url: Optional[str] = None  # í˜ì´ì§€ë³„ ì˜¤ë””ì˜¤ íŒŒì¼ URL

class StoryInfo(BaseModel):
    """ë™í™” ì •ë³´ (MongoDB)"""
    id: str
    title: str
    text: str
    pages: Optional[List[StoryPage]] = None  # í˜ì´ì§€ë³„ë¡œ ë‚˜ëˆˆ í…ìŠ¤íŠ¸ì™€ ì˜¤ë””ì˜¤
    audio_url: Optional[str] = None  # ì „ì²´ ì˜¤ë””ì˜¤ íŒŒì¼ URL (í•˜ìœ„ í˜¸í™˜)
    character_id: Optional[str] = None
    created_at: Optional[str] = None

class StoryListResponse(BaseModel):
    """ë™í™” ëª©ë¡ ì‘ë‹µ"""
    stories: List[StoryInfo]
    total: int

# ==================== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ====================

def load_characters_db():
    """ìºë¦­í„° ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ"""
    global characters_db
    if CHARACTERS_DB.exists():
        with open(CHARACTERS_DB, 'r', encoding='utf-8') as f:
            characters_db = json.load(f)
    else:
        characters_db = {}
    return characters_db

def save_characters_db():
    """ìºë¦­í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥"""
    with open(CHARACTERS_DB, 'w', encoding='utf-8') as f:
        json.dump(characters_db, f, indent=2, ensure_ascii=False)

def get_embedding_path(character_id: str) -> Path:
    """ìºë¦­í„° ì„ë² ë”© íŒŒì¼ ê²½ë¡œ"""
    return EMBEDDINGS_DIR / f"{character_id}.pt"

def load_character_embedding(character_id: str) -> torch.Tensor:
    """ìºë¦­í„° ì„ë² ë”© ë¡œë“œ"""
    embedding_path = get_embedding_path(character_id)
    if not embedding_path.exists():
        raise HTTPException(status_code=404, detail=f"Character '{character_id}' not found")
    
    try:
        embedding = torch.load(embedding_path, map_location=device)
        return embedding
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to load embedding: {str(e)}")

def generate_character_id(name: str) -> str:
    """ìºë¦­í„° ID ìƒì„± (ê³ ìœ  ID)"""
    import hashlib
    timestamp = datetime.now().isoformat()
    unique_string = f"{name}_{timestamp}"
    return hashlib.md5(unique_string.encode()).hexdigest()[:12]

def split_story_into_pages(text: str, max_chars_per_page: int = 200) -> List[StoryPage]:
    """
    ë™í™” í…ìŠ¤íŠ¸ë¥¼ í˜ì´ì§€ë¡œ ë‚˜ëˆ„ê¸°
    
    Args:
        text: ì „ì²´ ë™í™” í…ìŠ¤íŠ¸
        max_chars_per_page: í˜ì´ì§€ë‹¹ ìµœëŒ€ ë¬¸ì ìˆ˜ (ê¸°ë³¸ê°’: 200)
        
    Returns:
        List[StoryPage]: í˜ì´ì§€ë³„ë¡œ ë‚˜ëˆˆ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    if not text:
        return []
    
    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸° (ë§ˆì¹¨í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œ ê¸°ì¤€)
    import re
    sentences = re.split(r'([.!?ã€‚ï¼ï¼Ÿ]\s*)', text)
    
    # ë¬¸ì¥ë“¤ì„ í•©ì¹˜ë©´ì„œ í˜ì´ì§€ êµ¬ì„±
    pages = []
    current_page_text = ""
    current_page_num = 1
    
    i = 0
    while i < len(sentences):
        sentence = sentences[i]
        if i + 1 < len(sentences):
            sentence += sentences[i + 1]  # êµ¬ë¶„ì í¬í•¨
            i += 2
        else:
            i += 1
        
        # í˜„ì¬ í˜ì´ì§€ì— ë¬¸ì¥ ì¶”ê°€ ì‹œ ê¸¸ì´ ì²´í¬
        if len(current_page_text) + len(sentence) > max_chars_per_page and current_page_text:
            # í˜„ì¬ í˜ì´ì§€ ì €ì¥
            pages.append(StoryPage(
                page=current_page_num,
                text=current_page_text.strip(),
                audio_url=None  # ë‚˜ì¤‘ì— ì˜¤ë””ì˜¤ ìƒì„± ì‹œ ì—…ë°ì´íŠ¸
            ))
            current_page_text = sentence
            current_page_num += 1
        else:
            current_page_text += sentence
    
    # ë§ˆì§€ë§‰ í˜ì´ì§€ ì¶”ê°€
    if current_page_text.strip():
        pages.append(StoryPage(
            page=current_page_num,
            text=current_page_text.strip(),
            audio_url=None
        ))
    
    return pages

# ==================== ì‹œì‘/ì¢…ë£Œ ì´ë²¤íŠ¸ ====================

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ì‹œ ëª¨ë¸ ë¡œë“œ"""
    global model, mongodb_client, mongodb_db
    print("=" * 60)
    print("ğŸš€ Zonos Multi-Character TTS API Server Starting...")
    print("=" * 60)
    
    print("\nğŸ“¦ Loading Zonos model...")
    try:
        # Transformer ëª¨ë¸ (ë” ë¹ ë¦„)
        model = Zonos.from_pretrained("Zyphra/Zonos-v0.1-transformer", device=device)
        # Hybrid ëª¨ë¸ (ë” ê³ í’ˆì§ˆ)
        # model = Zonos.from_pretrained("Zyphra/Zonos-v0.1-hybrid", device=device)
        print(f"âœ… Model loaded successfully on {device}")
    except Exception as e:
        print(f"âŒ Failed to load model: {e}")
        raise
    
    print("\nğŸ“š Loading characters database...")
    load_characters_db()
    print(f"âœ… Loaded {len(characters_db)} characters")
    
    # MongoDB ì—°ê²°
    if MONGODB_AVAILABLE:
        print("\nğŸ—„ï¸ Connecting to MongoDB...")
        try:
            mongodb_uri = os.getenv("MONGODB_URI", "mongodb://localhost:27017/")
            mongodb_db_name = os.getenv("MONGODB_DB_NAME", "tallo")
            
            mongodb_client = MongoClient(mongodb_uri)
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            mongodb_client.admin.command('ping')
            mongodb_db = mongodb_client[mongodb_db_name]
            print(f"âœ… MongoDB connected: {mongodb_uri}")
            print(f"âœ… Database: {mongodb_db_name}")
        except ConnectionFailure as e:
            print(f"âš ï¸ MongoDB connection failed: {e}")
            print("âš ï¸ MongoDB features will be disabled")
            mongodb_client = None
            mongodb_db = None
        except Exception as e:
            print(f"âš ï¸ MongoDB error: {e}")
            mongodb_client = None
            mongodb_db = None
    else:
        print("\nâš ï¸ MongoDB not available (pymongo not installed)")
    
    print("\n" + "=" * 60)
    print("âœ¨ Server is ready!")
    print("ğŸ“– API Documentation: {IPì£¼ì†Œ:port}/docs")
    print("=" * 60 + "\n")

# ==================== API ì—”ë“œí¬ì¸íŠ¸ ====================

@app.get("/")
async def root():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "status": "running",
        "model": "Zonos-v0.1-transformer",
        "device": str(device),
        "total_characters": len(characters_db)
    }

@app.get("/characters", response_model=List[CharacterInfo])
async def list_characters():
    """
    ë“±ë¡ëœ ëª¨ë“  ìºë¦­í„° ëª©ë¡ ì¡°íšŒ
    
    Returns:
        List[CharacterInfo]: ìºë¦­í„° ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    load_characters_db()
    return [CharacterInfo(**char) for char in characters_db.values()]

@app.get("/characters/{character_id}", response_model=CharacterInfo)
async def get_character(character_id: str):
    """
    íŠ¹ì • ìºë¦­í„° ì •ë³´ ì¡°íšŒ
    
    Args:
        character_id: ìºë¦­í„° ID
        
    Returns:
        CharacterInfo: ìºë¦­í„° ìƒì„¸ ì •ë³´
    """
    if character_id not in characters_db:
        raise HTTPException(status_code=404, detail="Character not found")
    return CharacterInfo(**characters_db[character_id])

@app.post("/characters/create")
async def create_character(
    name: str = Form(...),
    description: str = Form(None),
    language: str = Form("ko"),  # í•œêµ­ì–´ ê¸°ë³¸ê°’
    reference_audio: UploadFile = File(...)
):
    """
    ìƒˆë¡œìš´ ìºë¦­í„° ìƒì„± (Speaker Embedding ì¶”ì¶œ ë° ì €ì¥)
    
    Args:
        name: ìºë¦­í„° ì´ë¦„
        description: ìºë¦­í„° ì„¤ëª…
        language: ì–¸ì–´ ì½”ë“œ
        reference_audio: ì°¸ì¡° ì˜¤ë””ì˜¤ íŒŒì¼ (10-30ì´ˆ ê¶Œì¥)
        
    Returns:
        CharacterInfo: ìƒì„±ëœ ìºë¦­í„° ì •ë³´
    """
    # 1. ê³ ìœ  ID ìƒì„±
    character_id = generate_character_id(name)
    
    # 2. ì„ì‹œ íŒŒì¼ë¡œ ì˜¤ë””ì˜¤ ì €ì¥
    temp_audio_path = None
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_file:
            content = await reference_audio.read()
            temp_file.write(content)
            temp_audio_path = temp_file.name
        
        # 3. ì˜¤ë””ì˜¤ ë¡œë“œ
        print(f"ğŸ“ Creating character '{name}' (ID: {character_id})")
        wav, sampling_rate = torchaudio.load(temp_audio_path)
        
        # 4. Speaker Embedding ìƒì„±
        print("ğŸ¤ Extracting speaker embedding...")
        speaker_embedding = model.make_speaker_embedding(wav, sampling_rate)
        
        # 5. Embedding ì €ì¥
        embedding_path = get_embedding_path(character_id)
        torch.save(speaker_embedding, embedding_path)
        print(f"ğŸ’¾ Saved embedding: {embedding_path}")
        
        # 6. ì°¸ì¡° ì˜¤ë””ì˜¤ ì €ì¥ (ì„ íƒì )
        ref_audio_path = REFERENCE_DIR / f"{character_id}.wav"
        torchaudio.save(str(ref_audio_path), wav, sampling_rate, backend="soundfile")
        
        # 7. ìºë¦­í„° ì •ë³´ ì €ì¥
        character_info = {
            "id": character_id,
            "name": name,
            "description": description,
            "language": language,
            "created_at": datetime.now().isoformat(),
            "reference_audio": str(ref_audio_path.relative_to(BASE_DIR))
        }
        
        characters_db[character_id] = character_info
        save_characters_db()
        
        print(f"âœ… Character '{name}' created successfully!")
        return CharacterInfo(**character_info)
        
    except Exception as e:
        print(f"âŒ Error creating character: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if temp_audio_path and os.path.exists(temp_audio_path):
            os.unlink(temp_audio_path)

@app.delete("/characters/{character_id}")
async def delete_character(character_id: str):
    """
    ìºë¦­í„° ì‚­ì œ
    
    Args:
        character_id: ì‚­ì œí•  ìºë¦­í„° ID
    """
    if character_id not in characters_db:
        raise HTTPException(status_code=404, detail="Character not found")
    
    # ì„ë² ë”© íŒŒì¼ ì‚­ì œ
    embedding_path = get_embedding_path(character_id)
    if embedding_path.exists():
        embedding_path.unlink()
    
    # ì°¸ì¡° ì˜¤ë””ì˜¤ ì‚­ì œ (ì„ íƒì )
    ref_audio_path = REFERENCE_DIR / f"{character_id}.wav"
    if ref_audio_path.exists():
        ref_audio_path.unlink()
    
    # DBì—ì„œ ì‚­ì œ
    del characters_db[character_id]
    save_characters_db()
    
    return {"message": f"Character '{character_id}' deleted successfully"}

@app.post("/tts/generate")
async def generate_tts(request: TTSRequest):
    """
    íŠ¹ì • ìºë¦­í„°ì˜ ëª©ì†Œë¦¬ë¡œ TTS ìƒì„±
    
    Args:
        request: TTS ìƒì„± ìš”ì²­ (text, character_id, language, etc.)
        
    Returns:
        FileResponse: ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼
    """
    try:
        # 1. ìºë¦­í„° í™•ì¸
        if request.character_id not in characters_db:
            raise HTTPException(status_code=404, detail="Character not found")
        
        # 2. Speaker Embedding ë¡œë“œ
        speaker_embedding = load_character_embedding(request.character_id)
        
        # 3. Conditioning ì¤€ë¹„
        # speaking_rate: 10=ëŠë¦¼, 15=ë³´í†µ, 30=ë¹ ë¦„ (phonemes per minute)
        # pitch_std: 20-45=ìì—°ìŠ¤ëŸ¬ì›€, 60-150=í‘œí˜„ë ¥ ìˆìŒ
        speaking_rate = request.speaking_rate if request.speaking_rate > 1.0 else 15.0
        cond_dict = make_cond_dict(
            text=request.text,
            speaker=speaker_embedding,
            language=request.language,
            speaking_rate=speaking_rate,
            pitch_std=30.0  # ìì—°ìŠ¤ëŸ¬ìš´ ì–µì–‘
        )
        
        # ê°ì • ì¶”ê°€ (ì„ íƒì )
        if request.emotion:
            # ZonosëŠ” ê°ì • ì œì–´ë¥¼ ìœ„í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì›í•©ë‹ˆë‹¤
            # ì˜ˆ: happiness, sadness, anger, fear
            if request.emotion in ["happy", "happiness"]:
                cond_dict["happiness"] = 0.7
            elif request.emotion in ["sad", "sadness"]:
                cond_dict["sadness"] = 0.7
            elif request.emotion in ["angry", "anger"]:
                cond_dict["anger"] = 0.7
            elif request.emotion == "fear":
                cond_dict["fear"] = 0.7
        
        conditioning = model.prepare_conditioning(cond_dict)
        
        # 4. TTS ìƒì„±
        print(f"ğŸ¤ Generating TTS for character '{request.character_id}'...")
        with torch.no_grad():
            # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì¡°ì •
            # í•œê¸€ì€ í† í°ì„ ë” ë§ì´ ì‚¬ìš©í•˜ë¯€ë¡œ ì—¬ìœ ìˆê²Œ ì„¤ì •
            text_length = len(request.text)
            if text_length < 10:
                max_tokens = 300  # ë§¤ìš° ì§§ì€ ë¬¸ì¥ (3-4ì´ˆ)
            elif text_length < 20:
                max_tokens = 500  # ì§§ì€ ë¬¸ì¥ (5-6ì´ˆ)
            elif text_length < 50:
                max_tokens = 800  # ì¤‘ê°„ ë¬¸ì¥ (8-10ì´ˆ)
            elif text_length < 100:
                max_tokens = 1200  # ê¸´ ë¬¸ì¥ (12-15ì´ˆ)
            else:
                max_tokens = 86 * 30  # ë§¤ìš° ê¸´ ë¬¸ì¥ (ê¸°ë³¸ê°’)
            
            # ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„° ì¡°ì • (ë” ì•ˆì •ì ì¸ ìƒì„±)
            codes = model.generate(
                conditioning, 
                max_new_tokens=max_tokens,
                sampling_params={"min_p": 0.1, "temperature": 1.0}
            )
            wavs = model.autoencoder.decode(codes).cpu()
        
        # 5. íŒŒì¼ ì €ì¥
        character_name = characters_db[request.character_id]["name"]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{character_name}_{timestamp}.wav"
        output_path = OUTPUTS_DIR / filename

        # TorchCodec ì˜¤ë¥˜ ë°©ì§€: backend='soundfile' ì‚¬ìš©
        torchaudio.save(
            str(output_path),
            wavs[0],
            model.autoencoder.sampling_rate,
            backend="soundfile"
        )
        
        print(f"âœ… TTS generated: {output_path}")
        return FileResponse(
            output_path,
            media_type="audio/wav",
            filename=filename
        )
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Error generating TTS: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/tts/batch")
async def batch_generate_tts(
    texts: List[str] = Form(...),
    character_id: str = Form(...),
    language: str = Form("ko")  # í•œêµ­ì–´ ê¸°ë³¸ê°’
):
    """
    ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ìƒì„± (ë°°ì¹˜ ì²˜ë¦¬)
    
    Args:
        texts: í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        character_id: ìºë¦­í„° ID
        language: ì–¸ì–´ ì½”ë“œ
        
    Returns:
        JSON: ìƒì„±ëœ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    if character_id not in characters_db:
        raise HTTPException(status_code=404, detail="Character not found")
    
    speaker_embedding = load_character_embedding(character_id)
    generated_files = []
    
    for idx, text in enumerate(texts):
        try:
            cond_dict = make_cond_dict(
                text=text,
                speaker=speaker_embedding,
                language=language
            )
            conditioning = model.prepare_conditioning(cond_dict)
            
            with torch.no_grad():
                # ë°°ì¹˜ ì²˜ë¦¬ë„ ê¸¸ì´ ì œí•œ ì ìš©
                text_length = len(text)
                max_tokens = min(400 if text_length < 50 else 600, 86 * 30)
                codes = model.generate(conditioning, max_new_tokens=max_tokens)
                wavs = model.autoencoder.decode(codes).cpu()
            
            filename = f"{character_id}_batch_{idx}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.wav"
            output_path = OUTPUTS_DIR / filename
            torchaudio.save(str(output_path), wavs[0], model.autoencoder.sampling_rate, backend="soundfile")
            
            generated_files.append({
                "index": idx,
                "text": text,
                "file": str(output_path.relative_to(BASE_DIR))
            })
            
        except Exception as e:
            print(f"Error generating batch item {idx}: {e}")
            generated_files.append({
                "index": idx,
                "text": text,
                "error": str(e)
            })
    
    return {"results": generated_files}

@app.get("/outputs/{filename}")
async def get_output_file(filename: str):
    """
    ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    
    Args:
        filename: íŒŒì¼ ì´ë¦„
    """
    file_path = OUTPUTS_DIR / filename
    if not file_path.exists():
        raise HTTPException(status_code=404, detail="File not found")
    return FileResponse(file_path, media_type="audio/wav")

@app.get("/health")
async def health_check():
    """ì„œë²„ í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "healthy",
        "model_loaded": model is not None,
        "device": str(device),
        "characters_count": len(characters_db)
    }

@app.post("/stories/pregenerate")
async def pregenerate_story_audio(request: PreGenerateStoryRequest):
    """
    ë™í™”ì±… ì „ì²´ í˜ì´ì§€ì˜ TTSë¥¼ ë¯¸ë¦¬ ìƒì„±í•˜ì—¬ ìºì‹±
    
    Args:
        request: character_idì™€ pages ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë§µí•‘
    """
    character_id = request.character_id
    
    # ìºë¦­í„° í™•ì¸
    if character_id not in characters_db:
        raise HTTPException(status_code=404, detail="Character not found")
    
    # Speaker Embedding ë¡œë“œ
    speaker_embedding = load_character_embedding(character_id)
    
    # ìºë¦­í„°ë³„ ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
    cache_dir = CACHE_DIR / character_id
    cache_dir.mkdir(exist_ok=True)
    
    generated_pages = []
    
    print(f"ğŸ“š Pre-generating story audio for character '{character_id}'...")
    
    for page_data in request.pages:
        page_num = page_data["page"]
        text = page_data["text"]
        
        try:
            # ì´ë¯¸ ìºì‹œëœ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
            cached_file = cache_dir / f"page_{page_num}.wav"
            
            if cached_file.exists():
                print(f"âœ… Page {page_num} already cached")
                audio_url = f"/cache/{character_id}/page_{page_num}.wav"
            else:
                # TTS ìƒì„±
                print(f"ğŸ¤ Generating page {page_num}...")
                cond_dict = make_cond_dict(
                    text=text,
                    speaker=speaker_embedding,
                    language="ko"
                )
                conditioning = model.prepare_conditioning(cond_dict)
                
                with torch.no_grad():
                    codes = model.generate(conditioning)
                    wavs = model.autoencoder.decode(codes).cpu()
                
                # íŒŒì¼ ì €ì¥
                torchaudio.save(
                    str(cached_file),
                    wavs[0],
                    model.autoencoder.sampling_rate,
                    backend="soundfile"
                )
                
                audio_url = f"/cache/{character_id}/page_{page_num}.wav"
                print(f"âœ… Page {page_num} generated and cached")
            
            generated_pages.append({
                "page": page_num,
                "text": text,
                "audio_url": audio_url
            })
            
        except Exception as e:
            print(f"âŒ Error generating page {page_num}: {e}")
            generated_pages.append({
                "page": page_num,
                "text": text,
                "error": str(e)
            })
    
    # ìºì‹œ ì •ë³´ ì €ì¥
    if character_id not in story_audio_cache:
        story_audio_cache[character_id] = {}
    
    for page_data in generated_pages:
        if "audio_url" in page_data:
            story_audio_cache[character_id][page_data["page"]] = page_data["audio_url"]
    
    return {
        "character_id": character_id,
        "total_pages": len(generated_pages),
        "pages": generated_pages
    }

@app.get("/cache/{character_id}/{filename}")
async def get_cached_audio(character_id: str, filename: str):
    """
    ìºì‹œëœ ì˜¤ë””ì˜¤ íŒŒì¼ ì œê³µ
    
    Args:
        character_id: ìºë¦­í„° ID
        filename: íŒŒì¼ëª…
    """
    file_path = CACHE_DIR / character_id / filename
    if not file_path.exists():
        raise HTTPException(status_code=404, detail="Cached audio not found")
    return FileResponse(file_path, media_type="audio/wav")

@app.get("/stories/audio/{character_id}")
async def get_story_audio_map(character_id: str):
    """
    íŠ¹ì • ìºë¦­í„°ì˜ ë™í™”ì±… ì˜¤ë””ì˜¤ ë§µí•‘ ì¡°íšŒ
    
    Returns:
        {page_num: audio_url} ë”•ì…”ë„ˆë¦¬
    """
    if character_id not in story_audio_cache:
        return {"character_id": character_id, "pages": {}}
    
    return {
        "character_id": character_id,
        "pages": story_audio_cache[character_id]
    }

# ==================== LLM API ì—”ë“œí¬ì¸íŠ¸ ====================

@app.post("/llm/chat", response_model=LLMChatResponse)
async def chat_with_llm(request: LLMChatRequest):
    """
    OpenAI LLMê³¼ ëŒ€í™”í•˜ê³ , ì„ íƒì ìœ¼ë¡œ TTSë¡œ ë³€í™˜
    
    Args:
        request: LLM ì±„íŒ… ìš”ì²­ (message, character_id, return_audio ë“±)
        
    Returns:
        LLMChatResponse: LLM ì‘ë‹µ í…ìŠ¤íŠ¸ ë° TTS ì˜¤ë””ì˜¤ URL (ì„ íƒ)
    """
    if not OPENAI_AVAILABLE:
        raise HTTPException(
            status_code=500,
            detail="OpenAI íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install openai'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”."
        )
    
    # OpenAI API í‚¤ í™•ì¸
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise HTTPException(
            status_code=500,
            detail="OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”."
        )
    
    try:
        # 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        system_prompt = request.system_prompt or "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ë™í™” ì‘ê°€ì…ë‹ˆë‹¤."
        if request.character_name:
            system_prompt += f" {request.character_name} ìºë¦­í„°ì˜ ì„±ê²©ìœ¼ë¡œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”."
        
        # 2. OpenAI LLM API í˜¸ì¶œ (ìµœì‹  API ë°©ì‹)
        # openai >= 1.0.0 ë²„ì „ ëŒ€ì‘
        try:
            from openai import AsyncOpenAI
            client = AsyncOpenAI(api_key=api_key)
            response = await client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": request.message}
                ],
                temperature=0.7,
                max_tokens=500
            )
            llm_text = response.choices[0].message.content
        except ImportError:
            # êµ¬ë²„ì „ openai (< 1.0.0) ëŒ€ì‘
            openai.api_key = api_key
            response = await openai.ChatCompletion.acreate(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": request.message}
                ],
                temperature=0.7,
                max_tokens=500
            )
            llm_text = response.choices[0].message.content
        
        audio_url = None
        
        # 4. TTS ìƒì„± (ìš”ì²­ëœ ê²½ìš°)
        if request.return_audio and request.character_id:
            if request.character_id not in characters_db:
                raise HTTPException(status_code=404, detail="Character not found")
            
            # Speaker Embedding ë¡œë“œ
            speaker_embedding = load_character_embedding(request.character_id)
            
            # TTS ìƒì„±
            # speaking_rate: 10=ëŠë¦¼, 15=ë³´í†µ, 30=ë¹ ë¦„
            # pitch_std: 20-45=ìì—°ìŠ¤ëŸ¬ì›€
            cond_dict = make_cond_dict(
                text=llm_text,
                speaker=speaker_embedding,
                language="ko",
                speaking_rate=15.0,
                pitch_std=30.0
            )
            conditioning = model.prepare_conditioning(cond_dict)
            
            with torch.no_grad():
                # LLM ì‘ë‹µ ê¸¸ì´ì— ë”°ë¼ í† í° ìˆ˜ ì œí•œ
                text_length = len(llm_text)
                if text_length < 20:
                    max_tokens = 500
                elif text_length < 50:
                    max_tokens = 800
                elif text_length < 100:
                    max_tokens = 1200
                else:
                    max_tokens = 86 * 30
                
                codes = model.generate(
                    conditioning, 
                    max_new_tokens=max_tokens,
                    sampling_params={"min_p": 0.1, "temperature": 1.0}
                )
                wavs = model.autoencoder.decode(codes).cpu()
            
            # íŒŒì¼ ì €ì¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"llm_{request.character_id}_{timestamp}.wav"
            output_path = OUTPUTS_DIR / filename
            
            torchaudio.save(
                str(output_path),
                wavs[0],
                model.autoencoder.sampling_rate,
                backend="soundfile"
            )
            
            audio_url = f"/outputs/{filename}"
            print(f"âœ… LLM + TTS generated: {output_path}")
        
        return LLMChatResponse(text=llm_text, audio_url=audio_url)
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Error in LLM chat: {e}")
        raise HTTPException(status_code=500, detail=f"LLM ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

# ==================== MongoDB ë™í™” API ì—”ë“œí¬ì¸íŠ¸ ====================

@app.get("/stories/debug")
async def debug_mongodb():
    """MongoDB ì—°ê²° ìƒíƒœ ë° ì»¬ë ‰ì…˜ ì •ë³´ ë””ë²„ê¹…"""
    debug_info = {
        "mongodb_available": MONGODB_AVAILABLE,
        "mongodb_connected": mongodb_db is not None,
        "database_name": os.getenv("MONGODB_DB_NAME", "not set"),
        "collections": [],
        "stories_count": 0,
        "error": None
    }
    
    if not MONGODB_AVAILABLE:
        debug_info["error"] = "pymongo not installed"
        return debug_info
    
    if mongodb_db is None:
        debug_info["error"] = "MongoDB not connected"
        return debug_info
    
    try:
        # ì»¬ë ‰ì…˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        debug_info["collections"] = mongodb_db.list_collection_names()
        
        # "texts" ì»¬ë ‰ì…˜ í™•ì¸
        if "texts" in debug_info["collections"]:
            stories_collection = mongodb_db["texts"]
            debug_info["stories_count"] = stories_collection.count_documents({})
            
            # ìƒ˜í”Œ ë¬¸ì„œ í•˜ë‚˜ ê°€ì ¸ì˜¤ê¸°
            sample = stories_collection.find_one()
            if sample:
                debug_info["sample_doc"] = {
                    "_id": str(sample.get("_id", "")),
                    "filename": sample.get("filename", ""),
                    "has_content": bool(sample.get("content", "")),
                    "content_length": len(sample.get("content", "")) if sample.get("content") else 0
                }
    except Exception as e:
        debug_info["error"] = str(e)
    
    return debug_info

@app.get("/stories/list", response_model=StoryListResponse)
async def list_stories(limit: int = 5):
    """
    MongoDBì—ì„œ ë™í™” ëª©ë¡ ì¡°íšŒ (ìµœëŒ€ 5ê°œ)
    
    Args:
        limit: ê°€ì ¸ì˜¬ ë™í™” ê°œìˆ˜ (ê¸°ë³¸ê°’: 5)
        
    Returns:
        StoryListResponse: ë™í™” ëª©ë¡
    """
    if not MONGODB_AVAILABLE or mongodb_db is None:
        raise HTTPException(
            status_code=500,
            detail="MongoDBê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. MONGODB_URI í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”."
        )
    
    try:
        # MongoDB ì»¬ë ‰ì…˜ ì´ë¦„: "texts" (ì‹¤ì œ ì»¬ë ‰ì…˜ ì´ë¦„)
        stories_collection = mongodb_db["texts"]
        
        # ìµœëŒ€ 5ê°œë¡œ ì œí•œ
        limit = min(limit, 5)
        
        # MongoDBì—ì„œ ë™í™” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        # created_atì´ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ _idë¡œ ì •ë ¬ (ìµœì‹ ìˆœ)
        stories_cursor = stories_collection.find().limit(limit).sort("_id", -1)
        stories_list = []
        
        for story_doc in stories_cursor:
            # MongoDB í•„ë“œëª…: filename, content
            filename = story_doc.get("filename", "")
            # .txt í™•ì¥ì ì œê±°í•˜ì—¬ ì œëª©ìœ¼ë¡œ ì‚¬ìš©
            title = filename.replace(".txt", "") if filename else "ì œëª© ì—†ìŒ"
            content = story_doc.get("content", "")
            
            # í˜ì´ì§€ë¡œ ë‚˜ëˆ„ê¸° (ë¬¸ì¥ ë‹¨ìœ„)
            pages = split_story_into_pages(content)
            
            story_info = StoryInfo(
                id=str(story_doc.get("_id", "")),
                title=title,
                text=content,  # ì „ì²´ í…ìŠ¤íŠ¸ (í•˜ìœ„ í˜¸í™˜)
                pages=pages,  # í˜ì´ì§€ë³„ë¡œ ë‚˜ëˆˆ í…ìŠ¤íŠ¸
                audio_url=story_doc.get("audio_url"),
                character_id=story_doc.get("character_id"),
                created_at=story_doc.get("uploadedAt") or story_doc.get("created_at")
            )
            stories_list.append(story_info)
        
        total = stories_collection.count_documents({})
        
        return StoryListResponse(
            stories=stories_list,
            total=total
        )
        
    except Exception as e:
        print(f"âŒ Error fetching stories: {e}")
        raise HTTPException(status_code=500, detail=f"ë™í™” ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")

@app.get("/stories/{story_id}", response_model=StoryInfo)
async def get_story(story_id: str):
    """
    íŠ¹ì • ë™í™” ì¡°íšŒ
    
    Args:
        story_id: ë™í™” ID
        
    Returns:
        StoryInfo: ë™í™” ì •ë³´
    """
    if not MONGODB_AVAILABLE or mongodb_db is None:
        raise HTTPException(
            status_code=500,
            detail="MongoDBê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        )
    
    try:
        from bson import ObjectId
        stories_collection = mongodb_db["texts"]
        
        story_doc = stories_collection.find_one({"_id": ObjectId(story_id)})
        
        if not story_doc:
            raise HTTPException(status_code=404, detail="Story not found")
        
        filename = story_doc.get("filename", "")
        title = filename.replace(".txt", "") if filename else "ì œëª© ì—†ìŒ"
        content = story_doc.get("content", "")
        pages = split_story_into_pages(content)
        
        return StoryInfo(
            id=str(story_doc.get("_id", "")),
            title=title,
            text=content,
            pages=pages,
            audio_url=story_doc.get("audio_url"),
            character_id=story_doc.get("character_id"),
            created_at=story_doc.get("uploadedAt") or story_doc.get("created_at")
        )
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Error fetching story: {e}")
        raise HTTPException(status_code=500, detail=f"ë™í™” ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")

@app.get("/stories/{story_id}/audio")
async def get_story_audio(story_id: str):
    """
    ë™í™”ì˜ ë¯¸ë¦¬ ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ì¬ìƒ
    
    Args:
        story_id: ë™í™” ID
        
    Returns:
        FileResponse: ì˜¤ë””ì˜¤ íŒŒì¼
    """
    if not MONGODB_AVAILABLE or mongodb_db is None:
        raise HTTPException(
            status_code=500,
            detail="MongoDBê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        )
    
    try:
        from bson import ObjectId
        stories_collection = mongodb_db["stories"]
        
        story_doc = stories_collection.find_one({"_id": ObjectId(story_id)})
        
        if not story_doc:
            raise HTTPException(status_code=404, detail="Story not found")
        
        audio_url = story_doc.get("audio_url")
        if not audio_url:
            raise HTTPException(status_code=404, detail="Audio file not found for this story")
        
        # audio_urlì´ ìƒëŒ€ ê²½ë¡œë©´ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        if audio_url.startswith("/"):
            audio_path = BASE_DIR / audio_url.lstrip("/")
        else:
            audio_path = Path(audio_url)
        
        if not audio_path.exists():
            raise HTTPException(status_code=404, detail="Audio file not found")
        
        return FileResponse(
            audio_path,
            media_type="audio/wav",
            filename=f"story_{story_id}.wav"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Error fetching story audio: {e}")
        raise HTTPException(status_code=500, detail=f"ì˜¤ë””ì˜¤ íŒŒì¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")

@app.post("/stories/{story_id}/chat", response_model=LLMChatResponse)
async def story_chat(story_id: str, request: LLMChatRequest):
    """
    ë™í™” ì¬ìƒ ì¤‘ ì±„íŒ… (ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ì§€ í›„ LLM + TTS ìƒì„±)
    
    Args:
        story_id: ë™í™” ID
        request: LLM ì±„íŒ… ìš”ì²­
        
    Returns:
        LLMChatResponse: LLM ì‘ë‹µ ë° TTS ì˜¤ë””ì˜¤ URL
    """
    # ê¸°ì¡´ LLM ì±„íŒ… ë¡œì§ ì‚¬ìš©
    # í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ì§€ëŠ” ì²˜ë¦¬í•´ì•¼ í•¨
    return await chat_with_llm(request)

@app.post("/stories/{story_id}/pregenerate-audio")
async def pregenerate_story_pages_audio(story_id: str, character_id: str):
    """
    ë™í™”ì˜ ëª¨ë“  í˜ì´ì§€ì— ëŒ€í•œ ì˜¤ë””ì˜¤ë¥¼ ë¯¸ë¦¬ ìƒì„±
    
    Args:
        story_id: ë™í™” ID
        character_id: ìºë¦­í„° ID
        
    Returns:
        ìƒì„±ëœ í˜ì´ì§€ë³„ ì˜¤ë””ì˜¤ ì •ë³´
    """
    if not MONGODB_AVAILABLE or mongodb_db is None:
        raise HTTPException(
            status_code=500,
            detail="MongoDBê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        )
    
    try:
        from bson import ObjectId
        stories_collection = mongodb_db["texts"]
        
        story_doc = stories_collection.find_one({"_id": ObjectId(story_id)})
        if not story_doc:
            raise HTTPException(status_code=404, detail="Story not found")
        
        # ìºë¦­í„° í™•ì¸
        if character_id not in characters_db:
            raise HTTPException(status_code=404, detail="Character not found")
        
        # Speaker Embedding ë¡œë“œ
        speaker_embedding = load_character_embedding(character_id)
        
        # ë™í™” í…ìŠ¤íŠ¸ë¥¼ í˜ì´ì§€ë¡œ ë‚˜ëˆ„ê¸°
        content = story_doc.get("content", "")
        pages = split_story_into_pages(content)
        
        # ìŠ¤í† ë¦¬ë³„ ì˜¤ë””ì˜¤ ë””ë ‰í† ë¦¬ ìƒì„±
        story_audio_dir = OUTPUTS_DIR / "stories" / story_id
        story_audio_dir.mkdir(parents=True, exist_ok=True)
        
        generated_pages = []
        
        print(f"ğŸ¤ Pre-generating audio for story '{story_id}' ({len(pages)} pages)...")
        
        for page in pages:
            try:
                # í˜ì´ì§€ë³„ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
                audio_filename = f"page_{page.page}.wav"
                audio_path = story_audio_dir / audio_filename
                
                # ì´ë¯¸ ìƒì„±ëœ íŒŒì¼ì´ ìˆìœ¼ë©´ ìŠ¤í‚µ
                if audio_path.exists():
                    print(f"âœ… Page {page.page} already exists, skipping...")
                    audio_url = f"/outputs/stories/{story_id}/{audio_filename}"
                    generated_pages.append({
                        "page": page.page,
                        "text": page.text,
                        "audio_url": audio_url
                    })
                    continue
                
                # TTS ìƒì„±
                print(f"ğŸ¤ Generating audio for page {page.page}...")
                cond_dict = make_cond_dict(
                    text=page.text,
                    speaker=speaker_embedding,
                    language="ko",
                    speaking_rate=15.0,
                    pitch_std=30.0
                )
                conditioning = model.prepare_conditioning(cond_dict)
                
                with torch.no_grad():
                    text_length = len(page.text)
                    if text_length < 20:
                        max_tokens = 500
                    elif text_length < 50:
                        max_tokens = 800
                    elif text_length < 100:
                        max_tokens = 1200
                    else:
                        max_tokens = 86 * 30
                    
                    codes = model.generate(
                        conditioning,
                        max_new_tokens=max_tokens,
                        sampling_params={"min_p": 0.1, "temperature": 1.0}
                    )
                    wavs = model.autoencoder.decode(codes).cpu()
                
                # íŒŒì¼ ì €ì¥
                torchaudio.save(
                    str(audio_path),
                    wavs[0],
                    model.autoencoder.sampling_rate,
                    backend="soundfile"
                )
                
                audio_url = f"/outputs/stories/{story_id}/{audio_filename}"
                generated_pages.append({
                    "page": page.page,
                    "text": page.text,
                    "audio_url": audio_url
                })
                
                print(f"âœ… Page {page.page} audio generated: {audio_path}")
                
            except Exception as e:
                print(f"âŒ Error generating page {page.page}: {e}")
                generated_pages.append({
                    "page": page.page,
                    "text": page.text,
                    "error": str(e)
                })
        
        # MongoDBì— í˜ì´ì§€ë³„ ì˜¤ë””ì˜¤ URL ì—…ë°ì´íŠ¸ (ì„ íƒì )
        # stories_collection.update_one(
        #     {"_id": ObjectId(story_id)},
        #     {"$set": {"pages_audio": generated_pages}}
        # )
        
        return {
            "story_id": story_id,
            "character_id": character_id,
            "total_pages": len(pages),
            "generated_pages": generated_pages
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Error pregenerating story audio: {e}")
        raise HTTPException(status_code=500, detail=f"ì˜¤ë””ì˜¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

@app.get("/outputs/stories/{story_id}/{filename}")
async def get_story_page_audio(story_id: str, filename: str):
    """
    ë™í™” í˜ì´ì§€ë³„ ì˜¤ë””ì˜¤ íŒŒì¼ ì œê³µ
    
    Args:
        story_id: ë™í™” ID
        filename: íŒŒì¼ëª… (ì˜ˆ: page_1.wav)
    """
    file_path = OUTPUTS_DIR / "stories" / story_id / filename
    if not file_path.exists():
        raise HTTPException(status_code=404, detail="Audio file not found")
    return FileResponse(file_path, media_type="audio/wav")

# ==================== ë©”ì¸ ì‹¤í–‰ ====================

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        app,
        host= "0.0.0.0",
        port=8000,
        log_level="info"
    )